---
title: "Log Reg"
output: html_document
date: "2024-11-14"
---

```{r}
library(conflicted)
library(tidyverse)
library(tidytext)
library(textstem)
library(rvest)
library(stopwords)
library(tokenizers)
library(tidymodels)
library(modelr)
library(Matrix)
library(sparsesvd)
library(glmnet)
library(qdapRegex)
tidymodels_prefer()
# path to activity files on repo
url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/activities/data/'

# load a few functions for the activity
source(paste(url, 'projection-functions.R', sep = ''))
```

```{r}
load('data/claims-clean-task-1.RData')
```

```{r, eval=FALSE}
data = claims_clean %>%
  select(c(.id, bclass, text_clean, heading_clean)) %>%
  mutate(.id = factor(.id))

data_heading = data %>%
  unnest_tokens(word, heading_clean) %>%
  anti_join(stop_words) %>%
  mutate(word = lemmatize_words(word)) %>%
  select(-text_clean) %>%
  count(.id, word) %>%
  bind_tf_idf(term = word, document = .id, n = n)

data_text = data %>%
  unnest_tokens(word, text_clean) %>%
  anti_join(stop_words) %>%
  mutate(word = lemmatize_words(word)) %>%
  select(-heading_clean) %>%
  count(.id, word) %>%
  bind_tf_idf(term = word, document = .id, n = n)

data_heading_wide = data_heading %>%
  pivot_wider(names_from = word, values_from = tf_idf, 
              values_fill = 0, id_cols = .id) %>%
  replace(is.na(.), 0)

data_text_wide = data_text %>%
  pivot_wider(names_from = word, values_from = tf_idf, 
              values_fill = 0, id_cols = .id) %>%
  replace(is.na(.), 0)

data_wide = full_join(data_heading_wide, data_text_wide, by = join_by(.id), 
                      multiple = 'all', keep = TRUE, 
                      relationship = 'one-to-one') %>%
  drop_na() %>%
  rename(.id = .id.x)

data_wide_1 = full_join(data_wide, data %>% select(c(.id, bclass)), by = join_by(.id)) %>%
  drop_na()

data_wide_final = data_wide_1 %>% select(-.id)
```

```{r}
# partition data
set.seed(102722)
partitions <- data_wide_1 %>% initial_split(prop = 0.7)

# separate DTM from labels
test_dtm <- testing(partitions) %>%
  select(-.id, -bclass)
test_labels <- testing(partitions) %>%
  select(.id, bclass)

# same, training set
train_dtm <- training(partitions) %>%
  select(-.id, -bclass)
train_labels <- training(partitions) %>%
  select(.id, bclass)

```

```{r}
# find projections based on training data
proj_out <- projection_fn(.dtm = train_dtm, .prop = 0.7)
train_dtm_projected <- proj_out$data

# how many components were used?
proj_out$n_pc
```

```{r}
train <- train_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected)

fit <- glm(..., data = train, ...)
```

```{r, eval=FALSE}
set.seed(1000)
all_split = initial_split(data_wide_final, prop = 0.7, strata = bclass)
all_train = training(all_split)
all_test = testing(all_split)
```

```{r, eval=FALSE}
data_recipe = recipe(bclass ~ ., 
                        data = all_train) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_pca(all_numeric(), threshold = .75)

prep(data_recipe) %>%
  bake(new_data = all_train)
```

```{r, eval=FALSE}
log_reg = logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

all_log_wkflow = workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(data_recipe)

all_log_fit = fit(all_log_wkflow, all_train)

all_log_roc = augment(all_log_fit, all_test) %>% 
  roc_auc(survived, .pred_Yes)
```

